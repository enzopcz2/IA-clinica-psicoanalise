<h1 align="center">
  <h1 align="center">IA ClÃ­nica de PsicoanÃ¡lise</h1>
  <br>
</h1>

## ğŸ“Œ **Sobre o Projeto**
Este projeto implementa um pipeline de anÃ¡lise clÃ­nica textual voltado ao contexto de psicologia/psicanÃ¡lise, utilizando modelos de linguagem (LLMs) para gerar hipÃ³teses, temas, significantes e avaliaÃ§Ãµes de risco a partir de textos livres. O foco principal nÃ£o Ã© apenas gerar texto, mas garantir consistÃªncia estrutural e validaÃ§Ã£o semÃ¢ntica mÃ­nima, utilizando Pydantic como camada de verificaÃ§Ã£o clÃ­nica.

# âš™ï¸ Como rodar o projeto

### 1ï¸âƒ£ PrÃ©-requisitos

- Python **3.10+**
- Conta OpenAI com **billing ativo**
- DependÃªncias:
  - `pydantic`
  - `langgraph`
  - `openai`

Instale as dependÃªncias:

```bash
pip install pydantic langgraph openai
```

### 2ï¸âƒ£ Configurar variÃ¡vel de ambiente

Defina sua chave da OpenAI

```bash
export OPENAI_API_KEY="sua_chave_aqui"
```

Ou no Windows (PowerShell)

```bash
setx OPENAI_API_KEY "sua_chave_aqui"
```

### 3ï¸âƒ£ Escolher versÃ£o do prompt e colocar texto clÃ­nico

O prompt ativo Ã© definido no main():

```bash
def main(prompt_version: str = "v2"):
```

Para trocar o prompt, basta alterar o valor de v2 para v1, ou vice-versa.

O programa suporta 2 textos clÃ­nicos para anÃ¡lise por vez, coloque eles dentro dos arquivos:

```text
data/input
â”œâ”€â”€ text_1.txt
â””â”€â”€ text_2.txt
```

Caso possua apenas 1 texto, deixe o outro arquivo em branco.

### 4ï¸âƒ£ Executar o pipeline

Rode o comando:

```bash
python pipeline.py
```

Ao final da execuÃ§Ã£o, serÃ¡ gerado o arquivo:

```text
results.json
```

### ğŸ”„ Como funciona o pipeline

O fluxo Ã© implementado com LangGraph, em um grafo linear de dois nÃ³s:
```text
[Generation Node] â†’ [Validation Node] â†’ END
```
ğŸ”¹ 1. Generation Node

- LÃª o texto de entrada
- Carrega o prompt selecionado
- Chama a OpenAI Responses API
- Retorna uma resposta em formato JSON (string)

ğŸ”¹ 2. Validation Node

- Valida a saÃ­da do modelo com Pydantic
- Garante: Tipos corretos, campos obrigatÃ³rios, regras mÃ­nimas (ex: listas nÃ£o vazias)
- Se a validaÃ§Ã£o falhar, o erro Ã© registrado de forma explÃ­cita

Esse desenho evita falhas silenciosas e impede inferÃªncias clÃ­nicas a partir de dados insuficientes ou malformados.

### ğŸ§© Como escolher o prompt
Os prompts ficam no diretÃ³rio:

```text
prompts/
â”œâ”€â”€ prompt_v1.txt
â””â”€â”€ prompt_v2.txt
```

Cada prompt pode definir:
- nÃ­vel de detalhamento clÃ­nico
- estilo da anÃ¡lise
- grau de cautela na avaliaÃ§Ã£o de risco

Isso permite experimentaÃ§Ã£o controlada sem alterar o cÃ³digo. 

As versÃµes dos prompts sÃ£o melhor explicadas em NOTES.md
## ğŸ“Š Como interpretar os resultados
O arquivo results.json possui a seguinte estrutura geral:

```json
{
  "prompt_version": "v2",
  "total": 2,
  "ok": 1,
  "failed": 1,
  "results": [...]
}
```

ğŸ”¹ Campos principais
- ok: indica se o texto passou todas as validaÃ§Ãµes
- errors: lista de erros estruturais ou clÃ­nicos
- output: resultado validado (quando ok = true)

âš ï¸ Falhas esperadas (importante)
Alguns textos podem falhar na validaÃ§Ã£o, por exemplo:

```text
Validation Error: List should have at least 1 item
at ('risk_assessment', 'signals')
```

Isso significa que o modelo nÃ£o encontrou sinais clÃ­nicos suficientes, o pipeline optou por nÃ£o inferir risco indevidamente. Esse comportamento Ã© intencional e desejÃ¡vel. O sistema prioriza rigor clÃ­nico em vez de forÃ§ar inferÃªncias a partir de dados pobres.

ğŸ“Œ Este projeto foi desenvolvido como um case tÃ©cnico, com foco em clareza,
robustez e responsabilidade no uso de modelos de linguagem.
